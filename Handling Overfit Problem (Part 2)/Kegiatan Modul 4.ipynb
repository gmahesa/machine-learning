{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kegiatan Modul 4.ipynb","provenance":[],"collapsed_sections":["LQFV9DKNdX1B","rfIlsm2AwQ3B","ANU5a8wRwEZM","6uPLgH20wdBz","nZMlM2ybwwVJ","kidFGq1SxFWb","_hnNfWj2zFzr","ca9jJmvOyUP3","Y_7_LkCpzjI9","7FFte3Dd0dP3","rq7qm2re1for"],"mount_file_id":"1X_E_PwNt7zjDtC5804Na6u1cemvOHGV7","authorship_tag":"ABX9TyP4HAIV6XKO4JsuH5F3IPuv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"u6kTqqtESNnc","colab_type":"text"},"source":["# **Kegiatan Modul 4**"]},{"cell_type":"markdown","metadata":{"id":"zQtmu9tIdbf4","colab_type":"text"},"source":["Dalam mendefinisikan model Machine Learing ada banyak cara untuk mendapatkan model dengan performa terbaik salah satunya adalah hyperparameter tuning. Contoh hyperparameter tuning telah diberikan dalam materi di modul ini, dalam kegiatan ini telah diberikan sedikit contoh lain untuk mendefinisikan model hyperparameter tuning dengan hparam. **Tugas anda dalam kegiatan modul kali ini adalah membuat model CNN dengan hyperparameter tuning dengan ketentuan wajib sebagai berikut :**\n","* Ketentuan wajib dataset minimal data 3000\n","* Lakukan eksperimen model untuk mencari model CNN dengan performa terbaik untuk mengklasifikasikan dataset yang sama dalam contoh dibawah.\n","* Definisikan minimal 5 model CNN dengan komposisi parameter yang berbeda-beda.\n","* Dalam mendefinisikan model, WAJIB melakukan tuning minimal pada 3 parameter model yang dirubah misalnya merubah jumlah neuron, nilai dropout, nilai lerning rate, jenis optimizer, jenis activation function dsb.\n","* Visualisasikan hasil evaluasi performa model. Anda dapat menggunakan plot pada umumnya seperti grafik loss dan accuracy dengan matplotib atau visualisasi interaktif menggunakan tensorboard seperti pada contoh dibawah.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M1OyrUJ6oQKE","colab_type":"text"},"source":["### **NOTE :** \n","Untuk mendapatkan penilaian syarat wajib diatas harus terpenuhi semua. Tunjukkan kepada asisten bahwa anda telah melakukan semua syarat wajib diatas serta jelaskan semampu anda.\n","\n","\n","**Poin penilaian :**\n","\n","* Menyelesaikan syarat wajib diatas untuk mendapatkan minimal **50 poin**\n","* Dapat menunjukkan dan menjelaskan hasil evaluasi masing-masing model yang digunakan. **5 poin**\n","* Dapat memvisualisasikan hasil evaluasi model dan menjelaskannya kepada asisten. **5 poin**\n","* Menggunakan maptplotlib atau seaborn untuk visualisasi loss dan accuracy. **10 poin**\n","* Menggunakan tensorboard untuk visualisasi hasil evaluasi model menggunakan hyperparameter tuning. **15 poin**\n","* Menggunakan Hparam untuk tuning model. **10 poin**\n","* Hasil accuracy model terbaik > 70% **nilai tambahan 5 poin** *\n","* Hasil accuracy model terbaik >= 80% **nilai tambahan 10 poin** *\n","* Hasil accuracy model terbaik >= 85% **nilai tambahan 15 poin** *\n","* Hasil accuracy model terbaik >= 90% **nilai tambahan 25 poin** *\n","* Hasil loss model terbaik < 10% **10 poin**\n","\n","**Ekstra 10 poin bagi anda yang dapat menjelaskan pekerjaan anda dengan baik dan tanpa plagiasi.**\n","\n","\\* *Pilih salah satu berdasarkan nilai akurasi terbaik*"]},{"cell_type":"markdown","metadata":{"id":"LQFV9DKNdX1B","colab_type":"text"},"source":["## **Contoh penggunaan hparam dan tensorboard:**"]},{"cell_type":"markdown","metadata":{"id":"rfIlsm2AwQ3B","colab_type":"text"},"source":["### Download dan unzip dataset."]},{"cell_type":"code","metadata":{"id":"J8MCsIjVeeuG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"status":"ok","timestamp":1596192383156,"user_tz":-420,"elapsed":4737,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"aa587386-86db-4892-e256-dab576856720"},"source":["# Download dataset\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip "],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-07-31 10:46:22--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 2607:f8b0:400e:c08::80, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 68606236 (65M) [application/zip]\n","Saving to: ‘cats_and_dogs_filtered.zip’\n","\n","cats_and_dogs_filte 100%[===================>]  65.43M  67.2MB/s    in 1.0s    \n","\n","2020-07-31 10:46:23 (67.2 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oAE_RyC3ijCS","colab_type":"code","colab":{}},"source":["!unzip \\cats_and_dogs_filtered.zip &> /dev/null "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANU5a8wRwEZM","colab_type":"text"},"source":["### Masuk ke lokasi tempat menyimpan dataset"]},{"cell_type":"code","metadata":{"id":"iFZq_hlgiflp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596193748602,"user_tz":-420,"elapsed":1068,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"c47ec6b7-e4fd-48d0-80b7-8e3337a8fbda"},"source":["%cd /content/drive/My Drive/RESEARCH CENTER/Kaggle"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/RESEARCH CENTER/Kaggle\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6uPLgH20wdBz","colab_type":"text"},"source":["### Definisi data generator"]},{"cell_type":"code","metadata":{"id":"2zZXbW-W1HBB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596193767730,"user_tz":-420,"elapsed":8307,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"5a8d4373-1c0b-4335-f6a8-3635b1fae9bb"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","train_datagen = ImageDataGenerator(width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   rescale=1./255,\n","                                   shear_range=0.2,\n","                                   horizontal_flip=True,\n","                                   fill_mode='nearest')\n","\n","training_set = train_datagen.flow_from_directory(\"cats_and_dogs_filtered/train/\",\n","                                                 target_size=(128,128),\n","                                                 color_mode=\"rgb\",\n","                                                 shuffle=False,\n","                                                 batch_size = 8,\n","                                                 class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LIoUs1Rl2DWs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596193771049,"user_tz":-420,"elapsed":7233,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"25297fa4-8d82-4aba-af3a-c563929969f0"},"source":["validation_datagen = ImageDataGenerator(width_shift_range=0.2,\n","                                        height_shift_range=0.2,\n","                                        rescale=1./255,\n","                                        shear_range=0.2,\n","                                        horizontal_flip=True,\n","                                        fill_mode='nearest')\n","\n","validation_set = validation_datagen.flow_from_directory(\"cats_and_dogs_filtered/validation/\",\n","                                                        target_size=(128,128),\n","                                                        color_mode=\"rgb\",\n","                                                        shuffle=False,\n","                                                        batch_size = 8,\n","                                                        class_mode='categorical')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 1000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nZMlM2ybwwVJ","colab_type":"text"},"source":["### Load TensorBoard notebook extension dan Hapus semua **logs** sebelumnya"]},{"cell_type":"code","metadata":{"id":"C1sc8yGyfUNz","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorboard.plugins.hparams import api as hp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KQl5OA_4cWd4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596206292817,"user_tz":-420,"elapsed":1634,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"ab99790f-7f10-41e0-d6c6-61a103bd3da9"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9t_9UZ6Aevsu","colab_type":"code","colab":{}},"source":["!rm -rf ./logs/ "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kidFGq1SxFWb","colab_type":"text"},"source":["### Definisikan hparam yang ingin digunakan. \n","\n","Semakin banyak hparam yang didefinisikan maka semakin banyak pula kombinasi hyperparameter digunakan untuk training model. Semakin banyak kombinasi maka semakin memakan banyak waktu (FYI : lama training model yang digunakan dalam contoh ini +/- 3-4 jam menggunakan GPU).\n","\n","Menyimpan semua summary hparam kedalam `logs/hparam_tuning` untuk digunakan oleh tensorboard dan sebagai penyimpanan sementara training information."]},{"cell_type":"code","metadata":{"id":"KtqStY2Wt3hC","colab_type":"code","colab":{}},"source":["HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 128]))\n","HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.5))\n","HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'adadelta']))\n","\n","METRIC_ACCURACY = 'accuracy'\n","\n","with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n","  hp.hparams_config(\n","    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n","    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hnNfWj2zFzr","colab_type":"text"},"source":["### Definisikan `x_val dan y_val` dari validation data untuk evaluasi model."]},{"cell_type":"code","metadata":{"id":"L2_dOLn4fx0b","colab_type":"code","colab":{}},"source":["xvl, yvl = zip(*(validation_set[i] for i in range(len(validation_set))))\n","x_val, y_val = np.vstack(xvl), np.vstack(yvl)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ca9jJmvOyUP3","colab_type":"text"},"source":["### Definisikan Model menggunakan hparam.\n","\n","Disini anda mendefinisikan model, compile model, training model secara bersamaan didalam fungsi `train_test_model`. Fungsi ini akan mengembalikan nilai akurasi rata-rata dari masing-masing model."]},{"cell_type":"code","metadata":{"id":"1F9wtViCuA5q","colab_type":"code","colab":{}},"source":["def train_test_model(hparams):\n","  model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(64, (5, 5), \n","                                                             activation=tf.nn.relu, \n","                                                             input_shape=(128,128,3)),\n","                                      tf.keras.layers.BatchNormalization(),\n","                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n","                                      tf.keras.layers.Conv2D(64, (5, 5), \n","                                                             activation=tf.nn.relu),\n","                                      tf.keras.layers.BatchNormalization(),\n","                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n","                                      tf.keras.layers.Conv2D(32, (5, 5), \n","                                                             activation=tf.nn.relu),\n","                                      tf.keras.layers.BatchNormalization(),\n","                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n","                                      tf.keras.layers.Flatten(),\n","                                      tf.keras.layers.Dense(hparams[HP_NUM_UNITS], \n","                                                            activation=tf.nn.relu),\n","                                      tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","                                      tf.keras.layers.Dense(32, activation=tf.nn.relu),\n","                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n","                                      tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n","                                      ])\n","\n","  model.compile(\n","      optimizer=hparams[HP_OPTIMIZER],\n","      loss='categorical_crossentropy',\n","      metrics=['accuracy'],\n","  )\n","\n","  model.fit(training_set, \n","            validation_data=validation_set, \n","            epochs=25,\n","            )\n","  _, accuracy = model.evaluate(x_val, y_val)\n","  return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y_7_LkCpzjI9","colab_type":"text"},"source":["### Definisikan fungsi `run` \n","\n","Hal ini bertujuan untuk melakukan log record hparams yang berisi summary dari hyperparameters dan final accuracy-nya."]},{"cell_type":"code","metadata":{"id":"EdmyowiD3RDK","colab_type":"code","colab":{}},"source":["def run(run_dir, hparams):\n","  with tf.summary.create_file_writer(run_dir).as_default():\n","    hp.hparams(hparams)  # record the values used in this trial\n","    accuracy = train_test_model(hparams)\n","    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FFte3Dd0dP3","colab_type":"text"},"source":["### Grid Search Training Model\n","\n","\n","Mulai jalankan training dan catat semuanya di bawah satu direktori induk.\n","Sekarang Anda dapat mencoba beberapa percobaan, latih masing-masing dengan serangkaian parameter yang berbeda. Untuk kesederhanaan, gunakan **grid search**: coba semua kombinasi parameter diskrit dan hanya batas bawah dan atas dari parameter bernilai riil. Untuk skenario yang lebih kompleks, mungkin lebih efektif untuk memilih setiap nilai hyperparameter secara acak (ini disebut **random search**). Ada metode yang lebih maju yang dapat digunakan.\n","\n","Jalankan beberapa percobaan, hal ini akan memakan waktu yang cukup lama:"]},{"cell_type":"code","metadata":{"id":"7wxllISrmPo5","colab_type":"code","colab":{}},"source":["['adam', 'sgd', 'adadelta', 'rmsprop', 'adamx', 'nadam']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0OoQ7cc940GI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596205397401,"user_tz":-420,"elapsed":6770759,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"dd23cc25-17b9-4180-e617-f8e5af6f280f"},"source":["session_num = 0\n","\n","for num_units in HP_NUM_UNITS.domain.values:\n","  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n","    for optimizer in HP_OPTIMIZER.domain.values:\n","      hparams = {\n","          HP_NUM_UNITS: num_units,\n","          HP_DROPOUT: dropout_rate,\n","          HP_OPTIMIZER: optimizer,\n","      }\n","      run_name = \"run-%d\" % session_num\n","      print('--- Starting trial: %s' % run_name)\n","      print({h.name: hparams[h] for h in hparams})\n","      run('logs/hparam_tuning/' + run_name, hparams)\n","      session_num += 1\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--- Starting trial: run-0\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adadelta'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.9160 - accuracy: 0.5055 - val_loss: 0.7463 - val_accuracy: 0.5000\n","Epoch 2/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9109 - accuracy: 0.5075 - val_loss: 0.8805 - val_accuracy: 0.4880\n","Epoch 3/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9210 - accuracy: 0.4890 - val_loss: 0.8764 - val_accuracy: 0.4550\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9016 - accuracy: 0.4930 - val_loss: 0.8704 - val_accuracy: 0.4090\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8983 - accuracy: 0.4865 - val_loss: 0.8384 - val_accuracy: 0.4560\n","Epoch 6/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.9099 - accuracy: 0.4865 - val_loss: 0.8651 - val_accuracy: 0.4650\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9195 - accuracy: 0.4800 - val_loss: 0.8567 - val_accuracy: 0.4340\n","Epoch 8/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.8839 - accuracy: 0.5010 - val_loss: 0.8455 - val_accuracy: 0.4530\n","Epoch 9/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8654 - accuracy: 0.5030 - val_loss: 0.8107 - val_accuracy: 0.4550\n","Epoch 10/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.8588 - accuracy: 0.5075 - val_loss: 0.8089 - val_accuracy: 0.4520\n","Epoch 11/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.8611 - accuracy: 0.4990 - val_loss: 0.8242 - val_accuracy: 0.4470\n","Epoch 12/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8549 - accuracy: 0.5100 - val_loss: 0.8589 - val_accuracy: 0.4110\n","Epoch 13/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8147 - accuracy: 0.5340 - val_loss: 0.8489 - val_accuracy: 0.4350\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8677 - accuracy: 0.4875 - val_loss: 0.8264 - val_accuracy: 0.4500\n","Epoch 15/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8745 - accuracy: 0.4960 - val_loss: 0.8460 - val_accuracy: 0.4340\n","Epoch 16/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8558 - accuracy: 0.5045 - val_loss: 0.8193 - val_accuracy: 0.4360\n","Epoch 17/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8807 - accuracy: 0.4775 - val_loss: 0.8470 - val_accuracy: 0.4180\n","Epoch 18/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8645 - accuracy: 0.4935 - val_loss: 0.8042 - val_accuracy: 0.4610\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8542 - accuracy: 0.4890 - val_loss: 0.8313 - val_accuracy: 0.4290\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8513 - accuracy: 0.4880 - val_loss: 0.8029 - val_accuracy: 0.4490\n","Epoch 21/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8301 - accuracy: 0.5180 - val_loss: 0.8105 - val_accuracy: 0.4580\n","Epoch 22/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.8372 - accuracy: 0.5000 - val_loss: 0.8151 - val_accuracy: 0.4590\n","Epoch 23/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8354 - accuracy: 0.4960 - val_loss: 0.7919 - val_accuracy: 0.4830\n","Epoch 24/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.8324 - accuracy: 0.4890 - val_loss: 0.8370 - val_accuracy: 0.4350\n","Epoch 25/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.8276 - accuracy: 0.5095 - val_loss: 0.8040 - val_accuracy: 0.4890\n","32/32 [==============================] - 0s 11ms/step - loss: 0.8100 - accuracy: 0.4630\n","--- Starting trial: run-1\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n","Epoch 1/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.7794 - accuracy: 0.4895 - val_loss: 0.7733 - val_accuracy: 0.5010\n","Epoch 2/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.7056 - accuracy: 0.5060 - val_loss: 0.6976 - val_accuracy: 0.5050\n","Epoch 3/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6962 - accuracy: 0.5085 - val_loss: 0.6908 - val_accuracy: 0.5300\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6972 - accuracy: 0.5065 - val_loss: 0.6891 - val_accuracy: 0.5340\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6885 - accuracy: 0.5475 - val_loss: 0.6898 - val_accuracy: 0.5620\n","Epoch 6/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6898 - accuracy: 0.5265 - val_loss: 0.6847 - val_accuracy: 0.5490\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6903 - accuracy: 0.5270 - val_loss: 0.6888 - val_accuracy: 0.5350\n","Epoch 8/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6858 - accuracy: 0.5440 - val_loss: 0.6875 - val_accuracy: 0.5620\n","Epoch 9/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6886 - accuracy: 0.5495 - val_loss: 0.6935 - val_accuracy: 0.5170\n","Epoch 10/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6851 - accuracy: 0.5505 - val_loss: 0.6974 - val_accuracy: 0.5070\n","Epoch 11/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6956 - accuracy: 0.5260 - val_loss: 0.6890 - val_accuracy: 0.5460\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6836 - accuracy: 0.5665 - val_loss: 0.6883 - val_accuracy: 0.5400\n","Epoch 13/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6859 - accuracy: 0.5670 - val_loss: 0.6894 - val_accuracy: 0.5620\n","Epoch 14/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6722 - accuracy: 0.5870 - val_loss: 0.6961 - val_accuracy: 0.5230\n","Epoch 15/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6736 - accuracy: 0.5825 - val_loss: 0.7026 - val_accuracy: 0.4990\n","Epoch 16/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6757 - accuracy: 0.5685 - val_loss: 0.7084 - val_accuracy: 0.5150\n","Epoch 17/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6653 - accuracy: 0.5935 - val_loss: 0.6756 - val_accuracy: 0.5740\n","Epoch 18/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6677 - accuracy: 0.6055 - val_loss: 0.7048 - val_accuracy: 0.5680\n","Epoch 19/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6593 - accuracy: 0.6010 - val_loss: 0.7174 - val_accuracy: 0.5160\n","Epoch 20/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6401 - accuracy: 0.6345 - val_loss: 0.7121 - val_accuracy: 0.5580\n","Epoch 21/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6461 - accuracy: 0.6355 - val_loss: 0.6923 - val_accuracy: 0.5740\n","Epoch 22/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6299 - accuracy: 0.6480 - val_loss: 0.6872 - val_accuracy: 0.5240\n","Epoch 23/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6193 - accuracy: 0.6715 - val_loss: 0.7219 - val_accuracy: 0.5420\n","Epoch 24/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6157 - accuracy: 0.6760 - val_loss: 0.7713 - val_accuracy: 0.5350\n","Epoch 25/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.5912 - accuracy: 0.7020 - val_loss: 0.7537 - val_accuracy: 0.5300\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7487 - accuracy: 0.5430\n","--- Starting trial: run-2\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'sgd'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.7559 - accuracy: 0.5385 - val_loss: 0.7141 - val_accuracy: 0.5020\n","Epoch 2/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6927 - accuracy: 0.5445 - val_loss: 0.6923 - val_accuracy: 0.5130\n","Epoch 3/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.7035 - accuracy: 0.5015 - val_loss: 0.6908 - val_accuracy: 0.5070\n","Epoch 4/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6941 - accuracy: 0.5320 - val_loss: 0.6898 - val_accuracy: 0.5240\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6881 - accuracy: 0.5455 - val_loss: 0.6873 - val_accuracy: 0.5380\n","Epoch 6/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6914 - accuracy: 0.5420 - val_loss: 0.6884 - val_accuracy: 0.5380\n","Epoch 7/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6907 - accuracy: 0.5335 - val_loss: 0.6890 - val_accuracy: 0.5360\n","Epoch 8/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6882 - accuracy: 0.5320 - val_loss: 0.6880 - val_accuracy: 0.5340\n","Epoch 9/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6916 - accuracy: 0.5365 - val_loss: 0.6844 - val_accuracy: 0.5560\n","Epoch 10/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6880 - accuracy: 0.5395 - val_loss: 0.6881 - val_accuracy: 0.5300\n","Epoch 11/25\n","250/250 [==============================] - 22s 87ms/step - loss: 0.6866 - accuracy: 0.5345 - val_loss: 0.6957 - val_accuracy: 0.5060\n","Epoch 12/25\n","250/250 [==============================] - 22s 87ms/step - loss: 0.6784 - accuracy: 0.5690 - val_loss: 0.6817 - val_accuracy: 0.5520\n","Epoch 13/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6861 - accuracy: 0.5585 - val_loss: 0.6899 - val_accuracy: 0.5190\n","Epoch 14/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6816 - accuracy: 0.5550 - val_loss: 0.6788 - val_accuracy: 0.5730\n","Epoch 15/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6738 - accuracy: 0.5795 - val_loss: 0.6806 - val_accuracy: 0.5640\n","Epoch 16/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6673 - accuracy: 0.6025 - val_loss: 0.6900 - val_accuracy: 0.5050\n","Epoch 17/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6673 - accuracy: 0.5795 - val_loss: 0.6825 - val_accuracy: 0.5690\n","Epoch 18/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6668 - accuracy: 0.5955 - val_loss: 0.6816 - val_accuracy: 0.5610\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6752 - accuracy: 0.5765 - val_loss: 0.6812 - val_accuracy: 0.5640\n","Epoch 20/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6700 - accuracy: 0.5805 - val_loss: 0.6802 - val_accuracy: 0.5530\n","Epoch 21/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6725 - accuracy: 0.5665 - val_loss: 0.7534 - val_accuracy: 0.5210\n","Epoch 22/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6706 - accuracy: 0.5965 - val_loss: 0.7111 - val_accuracy: 0.5500\n","Epoch 23/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6585 - accuracy: 0.5995 - val_loss: 0.6807 - val_accuracy: 0.5710\n","Epoch 24/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6648 - accuracy: 0.6075 - val_loss: 0.7137 - val_accuracy: 0.5360\n","Epoch 25/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6486 - accuracy: 0.6255 - val_loss: 0.6779 - val_accuracy: 0.5690\n","32/32 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5700\n","--- Starting trial: run-3\n","{'num_units': 64, 'dropout': 0.5, 'optimizer': 'adadelta'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.8333 - accuracy: 0.4900 - val_loss: 0.7135 - val_accuracy: 0.5000\n","Epoch 2/25\n","250/250 [==============================] - 23s 92ms/step - loss: 1.7340 - accuracy: 0.4995 - val_loss: 0.7403 - val_accuracy: 0.5010\n","Epoch 3/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.8027 - accuracy: 0.5000 - val_loss: 0.7230 - val_accuracy: 0.5060\n","Epoch 4/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.8302 - accuracy: 0.4910 - val_loss: 0.7246 - val_accuracy: 0.5170\n","Epoch 5/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.6911 - accuracy: 0.5210 - val_loss: 0.7254 - val_accuracy: 0.5030\n","Epoch 6/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.7474 - accuracy: 0.5045 - val_loss: 0.7240 - val_accuracy: 0.5010\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.7322 - accuracy: 0.4905 - val_loss: 0.7192 - val_accuracy: 0.5140\n","Epoch 8/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.7326 - accuracy: 0.5040 - val_loss: 0.7192 - val_accuracy: 0.5050\n","Epoch 9/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.7044 - accuracy: 0.5000 - val_loss: 0.7178 - val_accuracy: 0.5220\n","Epoch 10/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.7224 - accuracy: 0.4990 - val_loss: 0.7231 - val_accuracy: 0.5080\n","Epoch 11/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5886 - accuracy: 0.5125 - val_loss: 0.7190 - val_accuracy: 0.5090\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.6514 - accuracy: 0.4835 - val_loss: 0.7197 - val_accuracy: 0.5120\n","Epoch 13/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5997 - accuracy: 0.5180 - val_loss: 0.7107 - val_accuracy: 0.5040\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.6350 - accuracy: 0.5040 - val_loss: 0.7203 - val_accuracy: 0.5150\n","Epoch 15/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.6541 - accuracy: 0.4805 - val_loss: 0.7125 - val_accuracy: 0.5110\n","Epoch 16/25\n","250/250 [==============================] - 23s 92ms/step - loss: 1.5906 - accuracy: 0.4960 - val_loss: 0.7121 - val_accuracy: 0.5110\n","Epoch 17/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.5895 - accuracy: 0.5060 - val_loss: 0.7151 - val_accuracy: 0.5050\n","Epoch 18/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5216 - accuracy: 0.4975 - val_loss: 0.7185 - val_accuracy: 0.4980\n","Epoch 19/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.5079 - accuracy: 0.5090 - val_loss: 0.7218 - val_accuracy: 0.4830\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5540 - accuracy: 0.4985 - val_loss: 0.7149 - val_accuracy: 0.4890\n","Epoch 21/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5370 - accuracy: 0.4870 - val_loss: 0.7191 - val_accuracy: 0.4970\n","Epoch 22/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.4763 - accuracy: 0.4995 - val_loss: 0.7173 - val_accuracy: 0.5010\n","Epoch 23/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.5428 - accuracy: 0.4895 - val_loss: 0.7161 - val_accuracy: 0.5050\n","Epoch 24/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5006 - accuracy: 0.4975 - val_loss: 0.7117 - val_accuracy: 0.5090\n","Epoch 25/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.4197 - accuracy: 0.5105 - val_loss: 0.7104 - val_accuracy: 0.5080\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7087 - accuracy: 0.5110\n","--- Starting trial: run-4\n","{'num_units': 64, 'dropout': 0.5, 'optimizer': 'adam'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8545 - accuracy: 0.4850 - val_loss: 0.6974 - val_accuracy: 0.5110\n","Epoch 2/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.7162 - accuracy: 0.4800 - val_loss: 0.6954 - val_accuracy: 0.4880\n","Epoch 3/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.7022 - accuracy: 0.4845 - val_loss: 0.6945 - val_accuracy: 0.5290\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6970 - accuracy: 0.4770 - val_loss: 0.6932 - val_accuracy: 0.5350\n","Epoch 5/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6980 - accuracy: 0.4995 - val_loss: 0.6928 - val_accuracy: 0.5090\n","Epoch 6/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6947 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.5000\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6940 - accuracy: 0.4745 - val_loss: 0.6923 - val_accuracy: 0.5060\n","Epoch 8/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6941 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5200\n","Epoch 9/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6934 - accuracy: 0.5115 - val_loss: 0.6937 - val_accuracy: 0.4800\n","Epoch 10/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6968 - accuracy: 0.5090 - val_loss: 0.6961 - val_accuracy: 0.5120\n","Epoch 11/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6920 - accuracy: 0.5235 - val_loss: 0.6960 - val_accuracy: 0.4850\n","Epoch 12/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6949 - accuracy: 0.5340 - val_loss: 0.6898 - val_accuracy: 0.5230\n","Epoch 13/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6923 - accuracy: 0.5125 - val_loss: 0.6948 - val_accuracy: 0.4930\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6911 - accuracy: 0.5335 - val_loss: 0.7007 - val_accuracy: 0.4690\n","Epoch 15/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6911 - accuracy: 0.5290 - val_loss: 0.6901 - val_accuracy: 0.5310\n","Epoch 16/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6928 - accuracy: 0.5385 - val_loss: 0.6898 - val_accuracy: 0.5290\n","Epoch 17/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6919 - accuracy: 0.5270 - val_loss: 0.6940 - val_accuracy: 0.5290\n","Epoch 18/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6919 - val_accuracy: 0.5270\n","Epoch 19/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6927 - val_accuracy: 0.5330\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6877 - accuracy: 0.5680 - val_loss: 0.6929 - val_accuracy: 0.5050\n","Epoch 21/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6932 - accuracy: 0.5270 - val_loss: 0.6898 - val_accuracy: 0.5270\n","Epoch 22/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6875 - accuracy: 0.5595 - val_loss: 0.6901 - val_accuracy: 0.5440\n","Epoch 23/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6929 - accuracy: 0.5330 - val_loss: 0.6872 - val_accuracy: 0.5530\n","Epoch 24/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6807 - accuracy: 0.5630 - val_loss: 0.6921 - val_accuracy: 0.5350\n","Epoch 25/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6896 - accuracy: 0.5355 - val_loss: 0.7032 - val_accuracy: 0.5400\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7030 - accuracy: 0.5110\n","--- Starting trial: run-5\n","{'num_units': 64, 'dropout': 0.5, 'optimizer': 'sgd'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.7914 - accuracy: 0.5230 - val_loss: 0.7123 - val_accuracy: 0.5000\n","Epoch 2/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.7071 - accuracy: 0.4750 - val_loss: 0.6956 - val_accuracy: 0.4950\n","Epoch 3/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.7010 - accuracy: 0.4830 - val_loss: 0.6934 - val_accuracy: 0.5050\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6984 - accuracy: 0.4680 - val_loss: 0.6943 - val_accuracy: 0.5200\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6978 - accuracy: 0.4780 - val_loss: 0.6924 - val_accuracy: 0.5060\n","Epoch 6/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6948 - accuracy: 0.5185 - val_loss: 0.6938 - val_accuracy: 0.5160\n","Epoch 7/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6970 - accuracy: 0.4870 - val_loss: 0.6944 - val_accuracy: 0.5080\n","Epoch 8/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6958 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 9/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6949 - accuracy: 0.5125 - val_loss: 0.6917 - val_accuracy: 0.5160\n","Epoch 10/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6944 - accuracy: 0.5105 - val_loss: 0.7026 - val_accuracy: 0.5040\n","Epoch 11/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6956 - accuracy: 0.4680 - val_loss: 0.7078 - val_accuracy: 0.5070\n","Epoch 12/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6967 - accuracy: 0.4705 - val_loss: 0.7154 - val_accuracy: 0.4920\n","Epoch 13/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6951 - accuracy: 0.4780 - val_loss: 0.7008 - val_accuracy: 0.4910\n","Epoch 14/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6945 - accuracy: 0.5025 - val_loss: 0.7062 - val_accuracy: 0.5000\n","Epoch 15/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6942 - accuracy: 0.5040 - val_loss: 0.7016 - val_accuracy: 0.4780\n","Epoch 16/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6937 - accuracy: 0.4905 - val_loss: 0.7032 - val_accuracy: 0.5020\n","Epoch 17/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6963 - accuracy: 0.4535 - val_loss: 0.6983 - val_accuracy: 0.4860\n","Epoch 18/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6961 - accuracy: 0.4840 - val_loss: 0.6972 - val_accuracy: 0.4850\n","Epoch 19/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6945 - accuracy: 0.4680 - val_loss: 0.6925 - val_accuracy: 0.4930\n","Epoch 20/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6959 - accuracy: 0.4865 - val_loss: 0.6929 - val_accuracy: 0.5060\n","Epoch 21/25\n","250/250 [==============================] - 23s 93ms/step - loss: 0.6932 - accuracy: 0.4675 - val_loss: 0.6980 - val_accuracy: 0.5020\n","Epoch 22/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6950 - accuracy: 0.4870 - val_loss: 0.7032 - val_accuracy: 0.4960\n","Epoch 23/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6931 - accuracy: 0.4730 - val_loss: 0.6978 - val_accuracy: 0.5030\n","Epoch 24/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6905 - accuracy: 0.5030 - val_loss: 0.7151 - val_accuracy: 0.5010\n","Epoch 25/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6944 - accuracy: 0.5190 - val_loss: 0.7049 - val_accuracy: 0.4900\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7107 - accuracy: 0.4920\n","--- Starting trial: run-6\n","{'num_units': 128, 'dropout': 0.2, 'optimizer': 'adadelta'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.9234 - accuracy: 0.4990 - val_loss: 0.8459 - val_accuracy: 0.5000\n","Epoch 2/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.8079 - accuracy: 0.5010 - val_loss: 0.9128 - val_accuracy: 0.5000\n","Epoch 3/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.7139 - accuracy: 0.4995 - val_loss: 1.0087 - val_accuracy: 0.4980\n","Epoch 4/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.5619 - accuracy: 0.5015 - val_loss: 1.0150 - val_accuracy: 0.5000\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.5041 - accuracy: 0.5010 - val_loss: 0.9789 - val_accuracy: 0.5000\n","Epoch 6/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.4477 - accuracy: 0.5030 - val_loss: 0.9371 - val_accuracy: 0.4960\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.3113 - accuracy: 0.4945 - val_loss: 0.8924 - val_accuracy: 0.5000\n","Epoch 8/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.2381 - accuracy: 0.4970 - val_loss: 0.8696 - val_accuracy: 0.5020\n","Epoch 9/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.1833 - accuracy: 0.5015 - val_loss: 0.8567 - val_accuracy: 0.4980\n","Epoch 10/25\n","250/250 [==============================] - 23s 92ms/step - loss: 1.1341 - accuracy: 0.5030 - val_loss: 0.8169 - val_accuracy: 0.4990\n","Epoch 11/25\n","250/250 [==============================] - 22s 88ms/step - loss: 1.0937 - accuracy: 0.5000 - val_loss: 0.7951 - val_accuracy: 0.5060\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0675 - accuracy: 0.5000 - val_loss: 0.7938 - val_accuracy: 0.5040\n","Epoch 13/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.9983 - accuracy: 0.5035 - val_loss: 0.7699 - val_accuracy: 0.5000\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9558 - accuracy: 0.5020 - val_loss: 0.7566 - val_accuracy: 0.5170\n","Epoch 15/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.9062 - accuracy: 0.5065 - val_loss: 0.7519 - val_accuracy: 0.5050\n","Epoch 16/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9073 - accuracy: 0.5010 - val_loss: 0.7350 - val_accuracy: 0.5120\n","Epoch 17/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.8840 - accuracy: 0.5125 - val_loss: 0.7283 - val_accuracy: 0.5090\n","Epoch 18/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8615 - accuracy: 0.4945 - val_loss: 0.7182 - val_accuracy: 0.5120\n","Epoch 19/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8612 - accuracy: 0.4980 - val_loss: 0.7132 - val_accuracy: 0.5360\n","Epoch 20/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8387 - accuracy: 0.4970 - val_loss: 0.7082 - val_accuracy: 0.5230\n","Epoch 21/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8264 - accuracy: 0.4985 - val_loss: 0.7055 - val_accuracy: 0.5350\n","Epoch 22/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8208 - accuracy: 0.4950 - val_loss: 0.7036 - val_accuracy: 0.5390\n","Epoch 23/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.8173 - accuracy: 0.4860 - val_loss: 0.6942 - val_accuracy: 0.5530\n","Epoch 24/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.7939 - accuracy: 0.5110 - val_loss: 0.6974 - val_accuracy: 0.5370\n","Epoch 25/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.7788 - accuracy: 0.4905 - val_loss: 0.6975 - val_accuracy: 0.5400\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7001 - accuracy: 0.5240\n","--- Starting trial: run-7\n","{'num_units': 128, 'dropout': 0.2, 'optimizer': 'adam'}\n","Epoch 1/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.7545 - accuracy: 0.5000 - val_loss: 0.7093 - val_accuracy: 0.4920\n","Epoch 2/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6980 - accuracy: 0.5130 - val_loss: 0.7036 - val_accuracy: 0.5300\n","Epoch 3/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6992 - accuracy: 0.5130 - val_loss: 0.6913 - val_accuracy: 0.5350\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6924 - val_accuracy: 0.5110\n","Epoch 5/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6931 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5260\n","Epoch 6/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6859 - accuracy: 0.5440 - val_loss: 0.6952 - val_accuracy: 0.4990\n","Epoch 7/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6843 - accuracy: 0.5280 - val_loss: 0.6960 - val_accuracy: 0.5160\n","Epoch 8/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6916 - accuracy: 0.5350 - val_loss: 0.6957 - val_accuracy: 0.5210\n","Epoch 9/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6951 - accuracy: 0.5480 - val_loss: 0.6932 - val_accuracy: 0.5080\n","Epoch 10/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6832 - accuracy: 0.5535 - val_loss: 0.6884 - val_accuracy: 0.5360\n","Epoch 11/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6856 - accuracy: 0.5360 - val_loss: 0.6813 - val_accuracy: 0.5640\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6760 - accuracy: 0.5930 - val_loss: 0.6836 - val_accuracy: 0.5620\n","Epoch 13/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6784 - accuracy: 0.5960 - val_loss: 0.6825 - val_accuracy: 0.5540\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6735 - accuracy: 0.5825 - val_loss: 0.6788 - val_accuracy: 0.5720\n","Epoch 15/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6603 - accuracy: 0.6020 - val_loss: 0.7362 - val_accuracy: 0.5740\n","Epoch 16/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6664 - accuracy: 0.6165 - val_loss: 0.6829 - val_accuracy: 0.5750\n","Epoch 17/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6518 - accuracy: 0.6215 - val_loss: 0.6748 - val_accuracy: 0.5940\n","Epoch 18/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6554 - accuracy: 0.6145 - val_loss: 0.6724 - val_accuracy: 0.5830\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6394 - accuracy: 0.6590 - val_loss: 0.7022 - val_accuracy: 0.5590\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6364 - accuracy: 0.6465 - val_loss: 0.7190 - val_accuracy: 0.5450\n","Epoch 21/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6268 - accuracy: 0.6670 - val_loss: 0.6751 - val_accuracy: 0.5820\n","Epoch 22/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.5961 - accuracy: 0.6810 - val_loss: 0.6983 - val_accuracy: 0.5710\n","Epoch 23/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.5812 - accuracy: 0.6980 - val_loss: 0.7033 - val_accuracy: 0.5710\n","Epoch 24/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.5583 - accuracy: 0.7225 - val_loss: 0.7892 - val_accuracy: 0.5670\n","Epoch 25/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.7067 - val_accuracy: 0.5840\n","32/32 [==============================] - 0s 12ms/step - loss: 0.7237 - accuracy: 0.5790\n","--- Starting trial: run-8\n","{'num_units': 128, 'dropout': 0.2, 'optimizer': 'sgd'}\n","Epoch 1/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.7577 - accuracy: 0.4755 - val_loss: 0.7181 - val_accuracy: 0.4980\n","Epoch 2/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6933 - accuracy: 0.5300 - val_loss: 0.7014 - val_accuracy: 0.5080\n","Epoch 3/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6951 - accuracy: 0.5215 - val_loss: 0.6885 - val_accuracy: 0.5430\n","Epoch 4/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6927 - accuracy: 0.5270 - val_loss: 0.6874 - val_accuracy: 0.5550\n","Epoch 5/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6863 - val_accuracy: 0.5690\n","Epoch 6/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6863 - accuracy: 0.5530 - val_loss: 0.7012 - val_accuracy: 0.5100\n","Epoch 7/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6874 - accuracy: 0.5425 - val_loss: 0.6887 - val_accuracy: 0.5580\n","Epoch 8/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6850 - accuracy: 0.5485 - val_loss: 0.6768 - val_accuracy: 0.5930\n","Epoch 9/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6773 - accuracy: 0.5550 - val_loss: 0.6819 - val_accuracy: 0.5550\n","Epoch 10/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6843 - accuracy: 0.5480 - val_loss: 0.6860 - val_accuracy: 0.5560\n","Epoch 11/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6871 - accuracy: 0.5490 - val_loss: 0.6776 - val_accuracy: 0.5870\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6736 - accuracy: 0.5860 - val_loss: 0.6975 - val_accuracy: 0.5320\n","Epoch 13/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6795 - accuracy: 0.5635 - val_loss: 0.6801 - val_accuracy: 0.5620\n","Epoch 14/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6736 - accuracy: 0.5700 - val_loss: 0.6740 - val_accuracy: 0.6060\n","Epoch 15/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6791 - accuracy: 0.5555 - val_loss: 0.6849 - val_accuracy: 0.5780\n","Epoch 16/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6750 - accuracy: 0.5860 - val_loss: 0.6866 - val_accuracy: 0.5800\n","Epoch 17/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6709 - accuracy: 0.5780 - val_loss: 0.6700 - val_accuracy: 0.6090\n","Epoch 18/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6790 - accuracy: 0.5685 - val_loss: 0.6964 - val_accuracy: 0.5510\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6716 - accuracy: 0.5800 - val_loss: 0.6744 - val_accuracy: 0.5770\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6697 - accuracy: 0.5955 - val_loss: 0.6725 - val_accuracy: 0.5830\n","Epoch 21/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6621 - accuracy: 0.5975 - val_loss: 0.6545 - val_accuracy: 0.6390\n","Epoch 22/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6632 - accuracy: 0.6015 - val_loss: 0.6810 - val_accuracy: 0.5740\n","Epoch 23/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6671 - accuracy: 0.5955 - val_loss: 0.6763 - val_accuracy: 0.5870\n","Epoch 24/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6488 - accuracy: 0.6195 - val_loss: 0.6787 - val_accuracy: 0.5910\n","Epoch 25/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6397 - accuracy: 0.6190 - val_loss: 0.6673 - val_accuracy: 0.5980\n","32/32 [==============================] - 0s 13ms/step - loss: 0.6685 - accuracy: 0.6050\n","--- Starting trial: run-9\n","{'num_units': 128, 'dropout': 0.5, 'optimizer': 'adadelta'}\n","Epoch 1/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.1908 - accuracy: 0.5095 - val_loss: 0.7034 - val_accuracy: 0.5000\n","Epoch 2/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.1894 - accuracy: 0.4885 - val_loss: 0.6947 - val_accuracy: 0.5250\n","Epoch 3/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.1757 - accuracy: 0.4935 - val_loss: 0.6934 - val_accuracy: 0.5300\n","Epoch 4/25\n","250/250 [==============================] - 23s 93ms/step - loss: 1.1351 - accuracy: 0.5080 - val_loss: 0.6941 - val_accuracy: 0.5060\n","Epoch 5/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.1112 - accuracy: 0.5065 - val_loss: 0.6952 - val_accuracy: 0.5090\n","Epoch 6/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.1176 - accuracy: 0.4945 - val_loss: 0.6896 - val_accuracy: 0.5320\n","Epoch 7/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.1032 - accuracy: 0.4995 - val_loss: 0.6920 - val_accuracy: 0.5190\n","Epoch 8/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.1088 - accuracy: 0.4965 - val_loss: 0.6944 - val_accuracy: 0.5160\n","Epoch 9/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.0489 - accuracy: 0.5100 - val_loss: 0.6936 - val_accuracy: 0.5280\n","Epoch 10/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.0780 - accuracy: 0.5055 - val_loss: 0.6921 - val_accuracy: 0.5320\n","Epoch 11/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.0674 - accuracy: 0.4940 - val_loss: 0.6949 - val_accuracy: 0.5050\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0637 - accuracy: 0.4900 - val_loss: 0.6946 - val_accuracy: 0.5230\n","Epoch 13/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0763 - accuracy: 0.5095 - val_loss: 0.6949 - val_accuracy: 0.4990\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0461 - accuracy: 0.5205 - val_loss: 0.6951 - val_accuracy: 0.5170\n","Epoch 15/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0481 - accuracy: 0.4925 - val_loss: 0.7018 - val_accuracy: 0.4860\n","Epoch 16/25\n","250/250 [==============================] - 22s 90ms/step - loss: 1.0303 - accuracy: 0.5040 - val_loss: 0.6916 - val_accuracy: 0.5270\n","Epoch 17/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0677 - accuracy: 0.5065 - val_loss: 0.6930 - val_accuracy: 0.5260\n","Epoch 18/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.0278 - accuracy: 0.5030 - val_loss: 0.6981 - val_accuracy: 0.5040\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9611 - accuracy: 0.5355 - val_loss: 0.6954 - val_accuracy: 0.5170\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 1.0103 - accuracy: 0.5035 - val_loss: 0.6930 - val_accuracy: 0.5210\n","Epoch 21/25\n","250/250 [==============================] - 23s 91ms/step - loss: 1.0109 - accuracy: 0.4960 - val_loss: 0.6909 - val_accuracy: 0.5230\n","Epoch 22/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.0047 - accuracy: 0.5000 - val_loss: 0.6994 - val_accuracy: 0.4720\n","Epoch 23/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.9741 - accuracy: 0.5150 - val_loss: 0.6958 - val_accuracy: 0.5270\n","Epoch 24/25\n","250/250 [==============================] - 23s 92ms/step - loss: 1.0214 - accuracy: 0.4960 - val_loss: 0.6920 - val_accuracy: 0.5280\n","Epoch 25/25\n","250/250 [==============================] - 23s 90ms/step - loss: 1.0246 - accuracy: 0.4930 - val_loss: 0.6916 - val_accuracy: 0.5240\n","32/32 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.5000\n","--- Starting trial: run-10\n","{'num_units': 128, 'dropout': 0.5, 'optimizer': 'adam'}\n","Epoch 1/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.8150 - accuracy: 0.5115 - val_loss: 0.6954 - val_accuracy: 0.5130\n","Epoch 2/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.7009 - accuracy: 0.4830 - val_loss: 0.6968 - val_accuracy: 0.5010\n","Epoch 3/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6960 - accuracy: 0.4805 - val_loss: 0.7105 - val_accuracy: 0.4880\n","Epoch 4/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6971 - accuracy: 0.4775 - val_loss: 0.6963 - val_accuracy: 0.4950\n","Epoch 5/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6932 - accuracy: 0.4950 - val_loss: 0.7204 - val_accuracy: 0.5020\n","Epoch 6/25\n","250/250 [==============================] - 23s 94ms/step - loss: 0.6989 - accuracy: 0.4630 - val_loss: 0.6923 - val_accuracy: 0.5270\n","Epoch 7/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6936 - accuracy: 0.4695 - val_loss: 0.6918 - val_accuracy: 0.5080\n","Epoch 8/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6939 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5090\n","Epoch 9/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6940 - accuracy: 0.4550 - val_loss: 0.6939 - val_accuracy: 0.4840\n","Epoch 10/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6942 - accuracy: 0.4995 - val_loss: 0.6890 - val_accuracy: 0.5260\n","Epoch 11/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6983 - accuracy: 0.4870 - val_loss: 0.6922 - val_accuracy: 0.5020\n","Epoch 12/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6933 - accuracy: 0.5080 - val_loss: 0.6904 - val_accuracy: 0.5600\n","Epoch 13/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6935 - accuracy: 0.4895 - val_loss: 0.6930 - val_accuracy: 0.4850\n","Epoch 14/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6926 - accuracy: 0.4845 - val_loss: 0.6917 - val_accuracy: 0.5140\n","Epoch 15/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6966 - accuracy: 0.5090 - val_loss: 0.6932 - val_accuracy: 0.4990\n","Epoch 16/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6911 - accuracy: 0.5155 - val_loss: 0.6917 - val_accuracy: 0.5060\n","Epoch 17/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6942 - val_accuracy: 0.5090\n","Epoch 18/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6923 - accuracy: 0.5040 - val_loss: 0.6927 - val_accuracy: 0.5090\n","Epoch 19/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6937 - accuracy: 0.5025 - val_loss: 0.6926 - val_accuracy: 0.5090\n","Epoch 20/25\n","250/250 [==============================] - 24s 95ms/step - loss: 0.6904 - accuracy: 0.5290 - val_loss: 0.6905 - val_accuracy: 0.5230\n","Epoch 21/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6944 - accuracy: 0.5370 - val_loss: 0.6882 - val_accuracy: 0.5330\n","Epoch 22/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6924 - accuracy: 0.5220 - val_loss: 0.6940 - val_accuracy: 0.5150\n","Epoch 23/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6939 - accuracy: 0.5355 - val_loss: 0.6899 - val_accuracy: 0.5270\n","Epoch 24/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6884 - accuracy: 0.5380 - val_loss: 0.6929 - val_accuracy: 0.5220\n","Epoch 25/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6916 - val_accuracy: 0.5160\n","32/32 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.5120\n","--- Starting trial: run-11\n","{'num_units': 128, 'dropout': 0.5, 'optimizer': 'sgd'}\n","Epoch 1/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.7657 - accuracy: 0.5165 - val_loss: 0.7123 - val_accuracy: 0.4890\n","Epoch 2/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.7042 - accuracy: 0.4890 - val_loss: 0.7081 - val_accuracy: 0.5230\n","Epoch 3/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6990 - accuracy: 0.4595 - val_loss: 0.7064 - val_accuracy: 0.5020\n","Epoch 4/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6966 - accuracy: 0.4990 - val_loss: 0.7018 - val_accuracy: 0.5200\n","Epoch 5/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6962 - accuracy: 0.4960 - val_loss: 0.7090 - val_accuracy: 0.5130\n","Epoch 6/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6956 - accuracy: 0.4950 - val_loss: 0.7006 - val_accuracy: 0.4950\n","Epoch 7/25\n","250/250 [==============================] - 23s 90ms/step - loss: 0.6966 - accuracy: 0.4760 - val_loss: 0.7005 - val_accuracy: 0.4910\n","Epoch 8/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6945 - accuracy: 0.4970 - val_loss: 0.7050 - val_accuracy: 0.5070\n","Epoch 9/25\n","250/250 [==============================] - 23s 92ms/step - loss: 0.6958 - accuracy: 0.4865 - val_loss: 0.7016 - val_accuracy: 0.5100\n","Epoch 10/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6943 - accuracy: 0.4975 - val_loss: 0.7014 - val_accuracy: 0.5190\n","Epoch 11/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6951 - accuracy: 0.4790 - val_loss: 0.7054 - val_accuracy: 0.5130\n","Epoch 12/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6947 - accuracy: 0.5115 - val_loss: 0.7283 - val_accuracy: 0.5000\n","Epoch 13/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6927 - accuracy: 0.4750 - val_loss: 0.7339 - val_accuracy: 0.4810\n","Epoch 14/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6928 - accuracy: 0.4805 - val_loss: 0.7480 - val_accuracy: 0.5010\n","Epoch 15/25\n","250/250 [==============================] - 22s 88ms/step - loss: 0.6960 - accuracy: 0.4825 - val_loss: 0.7477 - val_accuracy: 0.4990\n","Epoch 16/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6961 - accuracy: 0.4790 - val_loss: 0.7485 - val_accuracy: 0.5010\n","Epoch 17/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6940 - accuracy: 0.5040 - val_loss: 0.7472 - val_accuracy: 0.4990\n","Epoch 18/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6930 - accuracy: 0.4935 - val_loss: 0.7414 - val_accuracy: 0.4970\n","Epoch 19/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6941 - accuracy: 0.4980 - val_loss: 0.7325 - val_accuracy: 0.5040\n","Epoch 20/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6954 - accuracy: 0.4660 - val_loss: 0.7294 - val_accuracy: 0.5050\n","Epoch 21/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6934 - accuracy: 0.4855 - val_loss: 0.7336 - val_accuracy: 0.5010\n","Epoch 22/25\n","250/250 [==============================] - 23s 91ms/step - loss: 0.6937 - accuracy: 0.4735 - val_loss: 0.7401 - val_accuracy: 0.4810\n","Epoch 23/25\n","250/250 [==============================] - 22s 90ms/step - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.7593 - val_accuracy: 0.4990\n","Epoch 24/25\n","250/250 [==============================] - 22s 89ms/step - loss: 0.6929 - accuracy: 0.4830 - val_loss: 0.7596 - val_accuracy: 0.5050\n","Epoch 25/25\n","250/250 [==============================] - 22s 87ms/step - loss: 0.6943 - accuracy: 0.4980 - val_loss: 0.7341 - val_accuracy: 0.4900\n","32/32 [==============================] - 0s 11ms/step - loss: 0.7413 - accuracy: 0.4960\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rq7qm2re1for","colab_type":"text"},"source":["### Visualisasi hasil evaluasi semua model dengan hyperparameternya menggunakan Tensorboard"]},{"cell_type":"code","metadata":{"id":"5IeZTCpCQcrM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596206314244,"user_tz":-420,"elapsed":2320,"user":{"displayName":"MOCH. CHAMDANI MUSTAQIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh57Ra_V9ifihLO9Mj540p_dAob-93csybwpz-0=s64","userId":"11970535415389905352"}},"outputId":"479a2468-affb-4bc7-9f91-d73d13e4ef36"},"source":["%%bash\n","wget -q 'https://storage.googleapis.com/download.tensorflow.org/tensorboard/hparams_demo_logs.zip'\n","unzip -q hparams_demo_logs.zip -d logs/hparam_demo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["replace logs/hparam_demo/hparams_demo/0/events.out.tfevents.1550612933.goshri.c.googlers.com? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n","(EOF or read error, treating as \"[N]one\" ...)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0Fk-1aaWQjfU","colab_type":"code","colab":{}},"source":["%tensorboard --logdir logs/hparam_tuning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8ZfGdNCQyQC","colab_type":"code","colab":{}},"source":["!kill 5496"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xams_6XQWNrZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}